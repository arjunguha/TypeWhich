\documentclass{book}
\usepackage[T1]{fontenc}
\usepackage{fullpage}
\usepackage{palatino}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear}

\newcommand{\system}{\textsc{TypeWhich}\xspace}
\newcommand{\kw}[1]{\textbf{\texttt{#1}}}
\newcommand{\metavar}[1]{\textit{#1}}

\title{\system Guide}
\author{Luna Phipps-Costin, Carolyn Jane Anderson, Michael Greenberg, and Arjun Guha}

\begin{document}

\maketitle

\tableofcontents

\chapter{Introduction}

\system is a type migration tool for the gradually-typed lambda calculus with
several extensions. Its distinguishing characteristics are the following:

\begin{enumerate}

\item \system formulates type migration as a MaxSMT problem.

\item \system always produces a migration, as long as the input program is
   well-scoped.

\item \system can optimize for different properties: it can produce the most
informative types, or types that ensure compatibility with un-migrated code.

\end{enumerate}

Before you read the read of this guide or try to use \system, we strongly recommend
reading \citet{typewhich}, which describes \system in depth.

This repository contains the source code for \system. In addition to the
core type migration algorithm, the \system executable has several auxiliary
features:

\begin{enumerate}

  \item It has a parser for the Grift programming language, which we use to
  infer types for the Grift benchmarks from \citet{kuhlenschmidt:grift};

  \item It has an interpreter for the GTLC, which we use in validation;
  
  \item It has an implementation of the gradual type inference algorithm
  from \citet{rastogi:gti}; and

  \item It includes a framework for evaluating type migration algorithms,
  which we use to compare \system to several algorithms from the
  literature~\cite{rastogi:gti,campora:migrating,migeed:decidable,siek:gti}.

\end{enumerate}
%
Finally, this repository contains several gradual typing benchmarks:
%
\begin{enumerate}

     \item The ``challenge set'' from \citet{typewhich};
     
     \item The benchmarks from \citet{migeed:decidable}; and
     
     \item The benchmarks from \citet{kuhlenschmidt:grift}.

\end{enumerate}

This document will guide you though building \system, using it on example
programs, and using the evaluation framework to reproduce our experimental
results.

\section{Building and Testing \system}

\noindent
\textbf{For artifact evaluation, we strongly recommend using the \system
Virtual Machine and skipping this section.}

\paragraph{}
\system is built in Rust and uses Z3 under the hood. In principle, it should
work on macOS, Linux or Windows, though we have only tried it on macOS and
Linux. \emph{However}, our evaluation uses the implementation from
\citet{siek:gti}, which is an old piece of software that is difficult to build
on a modern platform. We have managed to compile it a Docker container and
produce a 32-bit Linux binary. It should be possible to build it for other
platforms, but it will require additional effort. Therefore, \textbf{we strongly
recommend using Linux to evaluate \system}.

\paragraph{Installing \system Dependencies}

To build \system from source, you will need:

\begin{enumerate}

\item The \href{https://rustup.rs/}{Rust language toolchain}.

\item The Z3 build dependencies and the ``usual'' build toolchain. On Ubuntu Linux, you can run the following
command to get them:

\begin{verbatim}
sudo apt-get install libz3-dev build-essential
\end{verbatim}

\item Python 3 and PyYAML to run the integration tests. These are installed by
default on most platforms. If you can run the following command successfully
then you already have them installed:
\begin{verbatim}
python3 -c "import yaml"
\end{verbatim}

\end{enumerate}

\paragraph{Installing Other Type Migration Tools}

\system does not require these dependencies, but they are necessary to reproduce
our evaluation.

\begin{enumerate}

\item \citet{migeed:decidable} is implemented in Haskell. We have written a
parser and printer for their tool that is compatible with \system. This
modified implementation is available at the following URL:

\url{https://github.com/arjunguha/migeed-palsberg-popl2020}

Build the tool as described in the repository, and then copy (or symlink) the
\texttt{MaxMigrate} program to \texttt{bin/MaxMigrate} in the \system
directory. On Linux, the executable is at:

\begin{verbatim}
migeed-palsberg-popl2020/.stack-work/install/x86_64-linux-tinfo6/
lts-13.25/8.6.5/bin/MaxMigrate
\end{verbatim}

\item \citet{siek:gti} is implemented in OCaml 3.12 (which is quite old).
The following repository has an implementation of the tool, with a modified
parser and printer that is compatible with \system:

\url{https://github.com/arjunguha/siek-vachharajani-dls2008}

Build the tool as described in the repository, and then copy (or symlink)
the \texttt{gtlc} program to \texttt{bin/gtubi} in the \system directory.

\textbf{Warning:} The repository builds a 32-bit Linux executable. You will
need to ensure that your Linux system has the libraries needed to run 32-bit
code.

\item \citet{campora:migrating} The following repository has our implementation
of the algorithm from \citet{campora:migrating}:
   
\url{https://github.com/arjunguha/mgt}

Build the tool as described in the repository and then copy (or symlink) the
the \texttt{mgt} program to \texttt{bin/mgt} in the \system directory.

\textbf{Note:} The original implementation by the authors of \citet{campora:migrating}
does not produce an ordinary migrated program as output. Instead, it produces a
BDD that can be interpreted as a family of programs. Our implementation of
their algorithm produces programs as output.

\end{enumerate}

\paragraph{Building and Testing}

Use \texttt{cargo} to build \system:

\begin{verbatim}
cargo build
\end{verbatim}

Run the unit tests:
\begin{verbatim}
cargo test
\end{verbatim}
You may see a few ignored tests, but \emph{no tests should fail}.

Test \system using the Grift benchmarks:
\begin{verbatim}
./test-runner.sh grift grift
\end{verbatim}
\emph{No tests should fail.}

Finally, run the GTLC benchmarks without any third-party tools:
\begin{verbatim}
cargo run -- benchmark benchmarks.yaml \
  --ignore Gtubi MGT MaxMigrate > test.results.yaml
\end{verbatim}
You will see debugging output (on standard error), but the results will
be saved to the YAML file. Compare these results to known good results:
\begin{verbatim}
./bin/yamldiff test.expected.yaml test.results.yaml
\end{verbatim}
\emph{You should see no output, which indicates that there are no
differences.}

\chapter{Artifact Evaluation: Getting Started}
\label{getting-started} 

This chapter assumes that you are either:

\begin{itemize}

     \item Using the \system Virtual Machine, or
     \item Have installed \system yourself, along with all the third party
     tools we use for evaluation.

\end{itemize}

To get started:

\begin{enumerate}
     
\item From the terminal, enter the \system directory:

\begin{verbatim}
cd typewhich
\end{verbatim}

\item Run the \system benchmarks, and output results to \texttt{results.yaml}:

\begin{verbatim}
./bin/TypeWhich benchmark > results.yaml
\end{verbatim}

This will take less than five minutes to complete. This command runs the
benchmark programs using five tools (and \system in two modes). For each
benchmark, you will thus see six lines of output (on standard error):
\begin{verbatim}
Running Gtubi on adversarial/01-farg-mismatch.gtlc ...
Running InsAndOuts on adversarial/01-farg-mismatch.gtlc ...
Running MGT on adversarial/01-farg-mismatch.gtlc ...
Running MaxMigrate on adversarial/01-farg-mismatch.gtlc ...
Running TypeWhich2 on adversarial/01-farg-mismatch.gtlc ...
Running TypeWhich on adversarial/01-farg-mismatch.gtlc ...
\end{verbatim}

The \texttt{InsAndOuts} tool does not terminate on three benchmarks, and
we kill it after some time. So, you will see \texttt{Killed} three times
in the output. This is expected.

\item Check that the results are identical to known good results:

\begin{verbatim}
./bin/yamldiff expected.yaml results.yaml
\end{verbatim}

You should see no output, which indicates that there are no differences.

\item [FILL] Grift benchmarks.

\end{enumerate}

At this point, it should be possible to validate the results in depth.

\chapter{Artifact Evaluation: Step by Step Guide}

\noindent
\textbf{This chapter assumes you have completed the steps in Chapter~\ref{getting-started}.}

\section{Claims To Validate}

The paper makes the following claims that can be validated:
\begin{enumerate}

    \item Figure~15 reports the results of several type migration tools on a
    a suite of benchmarks. Specifically, it categorizes them into several 
    columns. This artifact generates the figure, and the raw data and data
    analysis scripts can be validated.

    \item Section 6.5 runs \system on benchmarks written in Grift. These
    benchmarks have two versions: one that has no type annotations, and the other
    that has human-written type annotations. When run on the unannotated Grift
    benchmarks, \system calculates all but two of the human-written annotations.

    \item Section 6.6 reports that our full suite of benchmarks is 892 LOC, and
    \system{} takes three seconds to run on all of them. It will take longer in
    a virtual machine, but should be roughly the same. i.e., it will be significantly
    less than 30 seconds.

\end{enumerate}

The rest of this section will walk you through validating these results.

\subsection{GTLC Benchmarks on Multiple Tools}

In the previous chapter, we generated \texttt{results.yaml}. That
ran \system{} and all other tools on two suites of benchmarks:
\begin{enumerate}
        
\item The \texttt{migeed} directory contains the benchmarks
from \citet{migeed:decidable} written in the concrete syntax of \system.
     
\item The \texttt{adversarial} directory contains the ``challenge set'' from
the \system paper.
\end{enumerate}

The evaluation framework is driven by the file \texttt{benchmarks.yaml},
which specifies a list of type migration tools at the top, and is followed
by a list of benchmark files, with some additional information. The entire
benchmarking procedure is implemented in \texttt{src/benchmark.rs}:
\begin{enumerate}

\item It checks that the tool produces valid program, to verify that the tool
did not reject the program.

\item It runs the original program and the output of the tool and checks that
they produce the same result, to verify that the tool did not introduce a
runtime error.

\item In a gradually typed language, increasing type precision can make a
program incompatible with certain contexts. To check if this is the case, every
benchmark in the \textsc{yaml} file \emph{may} be accompanied by a context that
witnesses the incompatibility: the framework runs the original and migrated
program in the context, to check if they produce different results.

\item The framework counts the number of \texttt{any}s that are eliminated
by the migration tool. Every eliminated \texttt{any} improves precision, but
\emph{may or may not} introduce an incompatibility, but this requires human
judgement. For example, in the
program \verb|fun x . x + 1|, annotating ``x'' with \texttt{int} does not
introduce an incompatibility. However, in \verb|fun x . x|, annotating ``x''
with \texttt{int} is an incompatibility. The framework flags these results
for manual verification. However, it allows the input \textsc{yaml} to specify
expected outputs to suppress these warnings when desired.

\end{enumerate}

The file \texttt{results.yaml} is a copy of \texttt{benchmarks.yaml} with output
data added by the benchmarking framework. We use this file to generate Figure~15
in the paper. You should validate that table as follows:

\begin{enumerate}

\item Check that \texttt{results.yaml} does not have any errors: look for the
string ``Disaster'' in that file. It should not occur!

\item Regenerate the LaTeX snippet for the table with the following command:

\begin{verbatim}
./bin/TypeWhich latex-benchmark-summary results.yaml     
\end{verbatim}
The output that you will see will see is roughly the LaTeX code for Figure~15,
with two small differences: it prints \texttt{TypeWhich2} instead of \texttt{TypeWhichC}
and \texttt{TypeWhich} instead of \texttt{TypeWhichP}. However, the order of
rows and columns is exactly the same as the table in the paper. It should be
straightforward to check that the fractions in this output are exactly the fractions
reported in the table.

\end{enumerate}

\subsection{Grift Benchmarks with \system}

[FILL]

\subsection{Performance}

From the \system{} directory, run the following command:
\begin{verbatim}
time ./performance.sh
\end{verbatim}

The script will take roughly three seconds to complete. You can read the script
to verify that it runs \system{} on three suites of benchmarks:
\begin{enumerate}
     \item \texttt{migeed/*.gtlc}: the benchmarks from \citet{migeed:decidable},
     \item \texttt{adversarial/*.gtlc}: the ``challenge set'' from our paper, and
     \item \texttt{grift-suite/benchmarks/src/dyn/*.grift}: the benchmarks from \citet{kuhlenschmidt:grift}.
\end{enumerate}

\section{Exploring Type Migrations}

Our artifact includes several type migration tools, in addition to \system, and
we have hacked their parsers to work with the same concrete syntax, so that it
is easy to use any tool on the same program. We encourage you to try some out,
and to modify the benchmarks as well. Here are the available tools:

\begin{itemize}

\item To run \citet{migeed:decidable}:
     
\begin{verbatim}
./bin/MaxMigrate FILENAME.gtlc
\end{verbatim}

\item To run \citet{campora:migrating}:

\begin{verbatim}
./bin/mgt FILENAME.gtlc
\end{verbatim}

\item To run \citet{siek:gti}:

\begin{verbatim}
./bin/gtubi FILENAME.gtlc
\end{verbatim}

\item To run \citet{rastogi:gti}:
\begin{verbatim}
./bin/TypeWhich migrate --ins-and-outs FILENAME.gtlc
\end{verbatim}

\item To run \system{} and produce types that are safe in all contexts:
\begin{verbatim}
./bin/TypeWhich migrate FILENAME.gtlc
\end{verbatim}

\item To run \system{} and produce precise types that may not work in all
contexts:
\begin{verbatim}
./bin/TypeWhich migrate --precise FILENAME.gtlc
\end{verbatim}

\end{itemize}

\paragraph{Example}
Create a file called \texttt{input.gtlc} with the following contents:

\begin{verbatim}
(fun f. (fun y. f) (f 5)) (fun x. 10 + x)
\end{verbatim}

This program omits all type annotations: \system assumes that omitted
annotations are all \kw{any}.

We can migrate the the program using \system in two modes:

\begin{enumerate}

\item In \emph{compatibility mode}, \system infers types but maintains
compatibility with un-migrated code:

\begin{verbatim}
$ ./bin/TypeWhich migrate input.gtlc
(fun f:any -> int. (fun y:int. f) (f 5)) (fun x:any. 10 + x)
\end{verbatim}

\item In \emph{precise mode}, \system infers the most precise type that it
can, though that may come at the expense of compatibility:

\begin{verbatim}
$ ./bin/TypeWhich migrate --precise inpuy.gtlc
(fun f:int -> int. (fun y:int. f) (f 5)) (fun x:int. 10 + x)
\end{verbatim}
     
\end{enumerate}

\section{Input Language}\label{input-lang-gtlc}

\system supports a superset of the GTLC, written in the following syntax. Note
that the other tools do not support all the extensions documented below.

\begin{tabular}{rcll}
\metavar{b} & := & \kw{true} | \kw{false} & Boolean literal \\
\metavar{n} & := & ... | $-1$ | 0 | 1 | ... & Integer literals \\
\metavar{s} & := & \texttt{"..."} & String literals \\
\metavar{c} & := & b | n | s & Literals \\
\metavar{T} & := & \kw{any} & The unknown type \\
            & |  & \kw{int} & Integer type \\
            & |  & \kw{bool} & Boolean type \\
            & |  & \metavar{T}\textsubscript{1} \kw{->} \metavar{T}\textsubscript{2} & Function type \\
            & |  & \kw{(} \metavar{T} \kw{)} \\
\metavar{e} & := & \textit{x}  & Bound identifier \\
            & |  & \metavar{c} & Literal \\
            & |  & e \kw{:} T  & Type ascription \\
            & |  & \kw{(} \metavar{e} \kw{)} & Parenthesis \\
            & |  & \kw{fun} \metavar{x} \kw{.} \metavar{e} & Function \\
            & |  & \metavar{e}\textsubscript{1} \metavar{e}\textsubscript{2}
                 & Application \\
            & |  & \metavar{e}\textsubscript{1} \kw{+} \metavar{e}\textsubscript{2}
                 & Addition \\
            & |  & \metavar{e}\textsubscript{1} \kw{*} \metavar{e}\textsubscript{2}
                 & Multiplication \\
            & |  & \metavar{e}\textsubscript{1} \kw{=} \metavar{e}\textsubscript{2}
                 & Integer equality \\
            & |  & \metavar{e}\textsubscript{1} \kw{+?} \metavar{e}\textsubscript{2}
                 & Addition or string concatenation (overloaded) \\
            & |  & \kw{(}\metavar{e}\textsubscript{1}\kw{,}\metavar{e}\textsubscript{2}\kw{)}
                 & Pair \\
            & |  & \kw{fix} \metavar{f} \kw{.}\metavar{e}
                 & Fixpoint \\
            & |  & \kw{if} \metavar{e}\textsubscript{1} \kw{then} \metavar{e}\textsubscript{2} \kw{else} \metavar{e}\textsubscript{3}
                 & Conditional \\
            & |  & \kw{let} \metavar{x} \kw{=} \metavar{e}\textsubscript{1} \kw{in} \metavar{e}\textsubscript{2}
                 & Let binding \\
            & |  & \kw{let rec} \metavar{x} \kw{=} \metavar{e}\textsubscript{1} \kw{in} \metavar{e}\textsubscript{2}
                 & Recursive let binding \\

\end{tabular}

\chapter{Guide to Source Code}

The root TypeWhich directory includes a number of utilities, programs, and
source code (though most of \system is provided in src/):

\begin{enumerate}
    \item \texttt{adversarial/, grift-suite/benchmarks/, migeed/}: The three
    components of the \system benchmark suite, adversarial/ being original, and
    grift-suite/ and migeed/ adapted from the referenced research
    \item \texttt{doc/}: Source and render of this documentation
    \item \texttt{benchmarks.yaml}: This is the test harness configuration and data
    for the \system benchmarks framework, specifying to run the benchmarks and
    tools presented in the paper
    \item \texttt{expected.yaml}: Provides the expected behavior of the tool when
    configured with benchmarks.yaml
    \item \texttt{test.expected.yaml}: Provides the expected behavior of only
    \system / \citet{rastogi:gti} for testing the implementations
    \item \texttt{bin/}: Provides (and expects user to provide) symbolic links to tools
    \item \texttt{build.rs, Cargo.lock, Cargo.toml, target/}: Required build files for
    \system. Binaries are placed in target/
    \item \texttt{other-examples/}: Provides additional programs that are not
    interesting enough to be in the \system benchmark suite
    \item \texttt{grift\_inference.sh}: Evaluation tool for grift benchmarks
    which compares if types produced are exactly the same as the static types
    provided in the suite
    \item \texttt{performance.sh, test-runner.sh, run\_tool.sh}: Tools that run
    \system on more programs or in release mode
    \item \textbf{\texttt{src/}}: The \system implementation, including implemention of
    \citet{rastogi:gti}
\end{enumerate}

Within src/, the following files are found:

\begin{enumerate}
    \item \textbf{\texttt{benchmark.rs}, precision.rs}: Provides the \system benchmarking
    framework
    \item \textbf{\texttt{cgen.rs}}: Generates the documented constraints of the \system
    algorithm and performs type migration
    \item \texttt{eval.rs}: An interpreter for the GTLC with explicit coercions
    \item \texttt{insert\_coercions.rs}: Type-directed coercion insertion for the GTLC,
    used for the interpreter. Not related to type migration
    \item \texttt{grift.l, grift.y, grift.rs, lexer.l, parser.y, pretty.rs}: Parsers and
    printers for grift and the unified concrete syntax used by all tools
    \item \texttt{ins\_and\_outs/}: Our implementation of \citet{rastogi:gti}.
    \item \texttt{main.rs}: Entry point; options parsing
    \item \texttt{syntax.rs}: The language supported by \system
    \item \texttt{type\_check.rs}: Type-checking for programs with explicit coercions
    \item \texttt{z3\_state.rs}: Abstraction for the Z3 solver used for type inference
    in \system
\end{enumerate}

The core of the \system algorithm is found in cgen.rs. The constraints
specified in the paper are implemented in State::cgen (\textasciitilde{}line 52), with
comments resembling the notation from the paper. Of note are references to
\texttt{strengthen} and \texttt{weaken}, which are simply macros for
$(t1 = t2 \land w) \lor (t1 = * \land \texttt{ground(t2)} \land \neg w)$, w fresh; and
$(t1 = t2 \land w) \lor (t2 = * \land \texttt{ground(t1)} \land \neg w)$, w fresh
respectively. They are not to be confused with the \textsc{Weaken} function
from the paper.

State::negative\_any (\textasciitilde{}line 400) implements the \textsc{Weaken} algorithm from the paper.
typeinf\_options (\textasciitilde{}line 624) implements the \textsc{Migrate} algorithm in full.

\bibliography{doc}

\end{document}
